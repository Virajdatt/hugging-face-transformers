{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from transformers import pipeline"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Zero-Shot Classification"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "classifier = pipeline(\"zero-shot-classification\") # By default downloads roberta-large-mnli # model size is 1.33GB"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "No model was supplied, defaulted to roberta-large-mnli (https://huggingface.co/roberta-large-mnli)\n",
      "Downloading: 100%|██████████| 688/688 [00:00<00:00, 321kB/s]\n",
      "Downloading: 100%|██████████| 1.33G/1.33G [00:51<00:00, 27.5MB/s]\n",
      "2022-01-18 16:28:43.045018: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-01-18 16:28:43.045935: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Metal device set to: Apple M1\n",
      "\n",
      "systemMemory: 8.00 GB\n",
      "maxCacheSize: 2.67 GB\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at roberta-large-mnli.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n",
      "Downloading: 100%|██████████| 878k/878k [00:00<00:00, 4.11MB/s]\n",
      "Downloading: 100%|██████████| 446k/446k [00:00<00:00, 3.89MB/s]\n",
      "Downloading: 100%|██████████| 1.29M/1.29M [00:00<00:00, 4.43MB/s]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "classifier(\n",
    "    \"This is an amazing course to learn transformers\",\n",
    "    candidate_labels = ['rducation', 'politics', 'business']\n",
    ")"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'sequence': 'This is an amazing course to learn transformers',\n",
       " 'labels': ['rducation', 'politics', 'business'],\n",
       " 'scores': [0.5983677506446838, 0.20578426122665405, 0.1958479881286621]}"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Text Generation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "generator = pipeline(\"text-generation\", model = 'distilgpt2') # 313 MB model\n",
    "generator('Hey this course seems to be awesome',\n",
    "           max_length=30,\n",
    "           num_return_sequences=2,\n",
    "           ) # Will genrate the text, which will differ everytime"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Downloading: 100%|██████████| 762/762 [00:00<00:00, 236kB/s]\n",
      "Downloading: 100%|██████████| 313M/313M [00:11<00:00, 27.4MB/s]\n",
      "2022-01-18 16:32:34.944369: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at distilgpt2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n",
      "Downloading: 100%|██████████| 0.99M/0.99M [00:00<00:00, 6.54MB/s]\n",
      "Downloading: 100%|██████████| 446k/446k [00:00<00:00, 3.46MB/s]\n",
      "Downloading: 100%|██████████| 1.29M/1.29M [00:00<00:00, 7.79MB/s]\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[{'generated_text': 'Hey this course seems to be awesome for the first time: with a clear lead (and then some cool stuff, a bunch of great things!), it'},\n",
       " {'generated_text': \"Hey this course seems to be awesome. I'll definitely try it on your part. I promise that in a few months time there won't be the\"}]"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Text Completion (mask filling)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "mask = pipeline(\"fill-mask\") \n",
    "# This Will genrate the text, which will differ everytime\n",
    "generator('Hey this course seems to be <mask>', top_k=2) "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Token classification (Named Entity Recognaztion)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ner = pipeline('ner', grouped_entites=True)\n",
    "ner('My name is Virajdatt and I am learning Transformers')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Question Answering"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "question_answer = pipeline('question-answering')\n",
    "\n",
    "question_answer(\n",
    "    question = 'Where do you work?'\n",
    "    context = 'My name is Virajdatt and I work at Penn State'\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Text Summarization "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "summarizer = pipeline(\"summarization\")\n",
    "summarizer = ('''\n",
    "             Please include a paragraph that you want to summarize''')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Translation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "translator = pipe2('translation', )"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.7",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "9856851bd649d589f665b7dab82e57037201f90d2f14c285519476a7544379c3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}